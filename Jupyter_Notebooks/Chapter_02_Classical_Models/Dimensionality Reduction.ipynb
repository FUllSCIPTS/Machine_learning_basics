{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cee9c79-ae63-4675-87df-255510403af3",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"center\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "    <font face=\"IranNastaliq\" size=5>\n",
    "      به نام خدا\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=3>\n",
    "      دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "    </font>\n",
    "    <br>\n",
    "    <font color=blue size=5>\n",
    "      مقدمه‌ای بر یادگیری ماشین\n",
    "    </font>\n",
    "    <br>\n",
    "    <hr/>\n",
    "    <font color=red size=6>\n",
    "      فصل دوم:  کاهش بعد داده‌ها\n",
    "    </font>\n",
    "    <br>\n",
    "      نویسنده:‌ سینا مظاهری\n",
    "    <hr>\n",
    "<br>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba14717-4269-4af7-9901-62b59bd8a751",
   "metadata": {},
   "source": [
    "<span style=\"font-family: XB Zar; font-size: 5; \"><div dir=rtl><meta charset=\"UTF-8\">\n",
    "    <span style=\"color: red; font-size: large; \">1.مقدمه</span>\n",
    "    <br>\n",
    "    در مباحثی از یادگیری نظارت نشده که بیشتر بر روی کاهش بعد داده‌ها تمرکز دارند؛ یک هدف اصلی وجود دارد:  <b> پیدا کردن متغیر‌های تصادفی نهان پیوسته در ساختار مجموعه دادگان داده شده </b>.<br>\n",
    "    این عمل درست بر‌خلاف خوشه‌بندی می‌باشد که در آن ما به دنبال متغیر‌های نهان گسسته می‌باشیم. (پیدا کردن تعداد خوشه‌ها، بررسی رفتار خوشه‌ها، ...)<br>\n",
    "    روش‌های متعددی به منظور کاهش بعد داده‌ها وجود دارند. در این بخش به یکی از پرکاربردترین و معروف‌ترین آن‌ها می پردازیم.<br>\n",
    "    کاهش بعد‌ داده‌ها عموما به سه منظور صورت می‌گیرد:\n",
    "    <ul>\n",
    "        <li>نمایش داده‌ها یا همان Data Visualization برای مجموعه دادگانی که معمولا ابعاد بسیار بالایی دارند یعنی تعداد ابعاد از تعداد داده‌ها بسیار بسیار بیشتر است $(D \\gg N)$</li>\n",
    "        <li>در بعضی از روش‌های یادگیری ماشین نظارت شده که هدف به دست آوردن یک مقدار پیوسته یا گسسته است، کاهش بعد داده‌های ورودی، تاثیر بسزایی برروی عملکرد و نتایج خروجی آن می گذارد.</li> \n",
    "        <li>به منظور فشرده‌سازی داده‌ها استفاده می‌گردد.</li>\n",
    "    </ul>\n",
    "</div></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25574fb-0e37-45aa-99b8-db7fe7ff82e4",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\"><table><tr>\n",
    "<td> <img src=\"https://www.sqlservercentral.com/wp-content/uploads/legacy/c2362193dd68a81c6774bb9668f1178fc2cf4ad4/32947.jpg\" width=\"500\" style=\"vertical-align:middle\">\n",
    " <figcaption><center>شکل1. فشرده‌سازی تصویر</center></figcaption>\n",
    " </td>\n",
    "<td> <img src=\"https://www.researchgate.net/profile/Diego-Peluffo/publication/325363944/figure/fig1/AS:631693463539712@1527618866278/Dimensionality-reduction-effect-over-an-3D-artificial-Swiss-roll-manifold-the-2D.png\" width=\"500\" style=\"vertical-align:middle\">\n",
    " <figcaption><center>شکل2. کاهش بعد داده‌های سه بعدی به دو بعدی</center></figcaption> </td>\n",
    "</tr></table>\n",
    "    </div>\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc8de2-1826-41ac-a8a4-ba878c473e49",
   "metadata": {},
   "source": [
    "<span style=\"font-family: XB Zar; font-size: medium; \"><div dir=rtl><meta charset=\"UTF-8\">\n",
    "    <span style=\"color: red; font-size: large; \">2. تحلیل مولفه‌های اصلی یا PCA</span>\n",
    "    <br>\n",
    "    یکی از پرکاربردترین روش‌هایی که در کاهش بعد داده‌های یک مجموعه دادگان استفاده می‌شود\n",
    "    <b>تحلیل مولفه‌های اصلی </b>\n",
    "    می‌باشد. این روش از دو منظر قابل تعریف است که هر دو معادل یکدیگر می‌باشند:\n",
    "    <ul>\n",
    "  <li>نگاشت متعامد مجموعه دادگان به یک فضای برداری خطی با ابعاد کمتر از فضای برداری اصلی خود دادگان به گونه‌ای که واریانس دادگان تبدیل یافته بیشینه شود. به این زیرفضای کاهش یافته،\n",
    "      <b>زیرفضای اصلی (principal subspace)</b>\n",
    "      نیز گفته می‌شود.</li>\n",
    "  <li>نگاشت خطی‌ای می باشد که میانگین مربعات فاصله اقلیدسی بین داده اصلی و داده تبدیل یافته را کمینه می‌کند. </li>\n",
    "    </ul>\n",
    "</div></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd67a9-aea0-4d11-ac85-5f58269e2356",
   "metadata": {},
   "source": [
    "<div>\n",
    "<center>\n",
    "<img src=\"http://alexhwilliams.info/itsneuronalblog/img/pca/pca_two_views.png\" width=\"500\">\n",
    "</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e77070-39ad-4805-bcdd-d2074c89f3b2",
   "metadata": {},
   "source": [
    "<span style=\"font-family: XB Zar; font-size: medium; \"><div dir=rtl><meta charset=\"UTF-8\">\n",
    "    ما در این درسنامه به بررسی تعریف اول یعنی بیشینه سازی واریانس می پردازیم و بررسی درستی تعریف دوم را به خواننده واگذار می کنیم.\n",
    "</div></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339da8d-2ac7-43aa-8109-cdeaf40ade04",
   "metadata": {},
   "source": [
    "<span style=\"font-family: XB Zar; font-size: medium; \"><div dir=rtl><meta charset=\"UTF-8\">\n",
    "    <span style=\"color: red; font-size: large; \">1.2. بررسی تعریف بیشینه سازی واریانس در تحلیل مولفه های اصلی</span>\n",
    "    <br>\n",
    "    ابتدا فرص کنید که مجموعه دادگان\n",
    "    $ \\mathcal{D} = \\{ \\mathbf{x}_{1}, \\mathbf{x}_{2}, \\dots, \\mathbf{x}_{N}\\} $\n",
    "    به ما داده شده است. هر یک از\n",
    "    $ \\mathbf{x}_{i} $\n",
    "    یک بردار داده\n",
    "    $ D $\n",
    "     بعدی می‌باشد. حال ما این بردار‌ها را در درون یک ماتریس قرار می‌دهیم تا ماتریس دادگان یا \n",
    "    <b>Design Matrix</b>\n",
    "    $ \\mathbf{X}_{N \\times D} $\n",
    "    را تشکیل دهیم.\n",
    "    <br>\n",
    "    <br>\n",
    "    $$\\mathbf{X}_{N \\times D}=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x}^\\top_{1} \\\\\n",
    "\\mathbf{x}^\\top_{2} \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{x}^\\top_n \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    " x_{1}^{[1]} & x_{2}^{[1]} & \\cdots & x_{D}^{[1]} \\\\\n",
    " x_{1}^{[2]} & x_{2}^{[2]} & \\cdots & x_{D}^{[2]} \\\\\n",
    "\\vdots & \\vdots & \\cdots & \\vdots \\\\\n",
    " x_{1}^{[N]} & x_{2}^{[N]} & \\cdots & x_{D}^{[N]} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "<br>\n",
    "    ابتدا به بررسی میانگین نمونه‌ای و کوواریانس نمونه‌ای این ماتریس دادگان می‌پردازیم و سپس زیر فضای اصلی را میابیم \n",
    "</div></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac21f2-1e28-4dd6-b697-94b43704a873",
   "metadata": {},
   "source": [
    "<span style=\"font-family: XB Zar; font-size: medium; \"><div dir=rtl><meta charset=\"UTF-8\">\n",
    "    <span style=\"color: red; font-size: large; \">2.2. بررسی تعریف میانگین نمونه‌ای و واریانس نمونه‌ای ماتریس دادگان</span>\n",
    "    <br>\n",
    "    میانگین نمونه ای ماتریس دادگان را با\n",
    "    $\\bar{\\mathbf{x}}$\n",
    "    نمایش می دهیم و طبق تعریف خواهیم داشت:\n",
    "    <br>\n",
    "    $$\n",
    "    \\begin{split}\n",
    "    \\bar{\\mathbf{x}}_{D \\times 1} = \\frac{1}{N}\\mathbf{X}^\\top \\mathbf{1}\\quad, \\quad \\mathbf{1}_{N \\times 1} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}\n",
    "    \\end{split}\n",
    "    $$\n",
    "    <br>\n",
    "    ‌برای ماتریس کوواریانس نمونه‌ای که آن را با\n",
    "    $\\mathbf{S}$\n",
    "    نشان می‌دهیم نیز خواهیم داشت:\n",
    "    <br>\n",
    "     $$\n",
    "    \\mathbf{S}_{D \\times D} = \\frac{1}{N - 1}(\\mathbf{X} - \\mathbf{1}\\bar{\\mathbf{x}}^{\\top})^\\top(\\mathbf{X} - \\mathbf{1}\\bar{\\mathbf{x}}^{\\top}) = \\frac{1}{N - 1}\\displaystyle\\sum_{i = 1}^{N}(\\mathbf{x}_{i} - \\bar{\\mathbf{x}})(\\mathbf{x}_{i} - \\bar{\\mathbf{x}})^\\top\n",
    "    $$\n",
    "</div></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a806c-0d35-4945-ae77-ba0ee73af0b2",
   "metadata": {},
   "source": [
    "<span style=\"font-family: XB Zar; font-size: medium; \"><div dir=rtl><meta charset=\"UTF-8\">\n",
    "    چند نکته در مورد ماتریس کوواریانس نمونه‌ای\n",
    "    $ \\mathbf{S} $:\n",
    "    <ul>\n",
    "        <li>این ماتریس به وضوح یک ماتریس\n",
    "            <b> متقارن</b>\n",
    "        می‌باشد زیرا داریم:\n",
    "        $ \\mathbf{S}^{\\top} = \\mathbf{S} $\n",
    "        </li>\n",
    "        <li>\n",
    "            طبق قضیه‌ای در جبر خطی، هر ماتریس متقارن\n",
    "            ،$ D \\times D $\n",
    "            $D$\n",
    "            مقدار ویژه حقیقی به شکل\n",
    "            $ \\lambda_{1}, \\lambda_{2}, \\dots, \\lambda_{D} $\n",
    "            دارد که متناظر آن‌ها بردار ویژه‌ای وجود دارد به شکل\n",
    "            $\\{ \\mathbf{q}_{1}, \\mathbf{q}_{1}, \\dots, \\mathbf{q}_{D} \\}$\n",
    "که \n",
    "            <b>متعامد نرمال</b>\n",
    "             می‌باشند. نکته‌ای که وجود دارد آن است که بردارهای ویژه متعامد هستند اما لزوما نرم واحد ندارند. ما می‌توانیم آن را نرمال کنیم و با قرار دادن آن‌ها در ستون های ماتریس\n",
    "            $ \\mathbf{Q} $\n",
    "            ، پایه‌های متعامد نرمال را به دست بیاوریم.\n",
    "        </li>\n",
    "        <li>\n",
    "            طبق قضیه ای در جبر خطی، هر ماتریس متقارن یک ماتریس قطری شدنی است یعنی چنین تجزیه ای برای آن وجود دارد:\n",
    "            <br>\n",
    "            <br>\n",
    "            $$\\begin{split}\n",
    "            \\mathbf{S} = \\mathbf{Q}\\mathbf{\\Lambda}\\mathbf{Q}^{-1} = \\mathbf{Q}\\mathbf{\\Lambda}\\mathbf{Q}^{\\top} = \\displaystyle\\sum_{i = 1}^{D} \\lambda_{i}\\mathbf{q}_{i}\\mathbf{q}_{i}^{\\top}, \\quad \\mathbf{\\Lambda} = diag(\\lambda_{1}, \\lambda_{2}, \\dots, \\lambda_{D}), \\quad \\mathbf{Q}= \\begin{bmatrix}\n",
    "\\mathbf{q}_{1} & \\mathbf{q}_{1} & \\dots & \\mathbf{q}_{D}\n",
    "\\end{bmatrix}\n",
    "            \\end{split}\n",
    "            $$\n",
    "        </li>\n",
    "    </ul>\n",
    "</div></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d3c60-f2e7-45a5-9074-9c59b626a835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
